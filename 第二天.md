#  7.3、基于Prometheus的HPA自动伸缩



### 一、背景：

- Kubernetes集群规模大、动态变化快，而且容器化应用部署和服务治理机制的普及，传统的基础设施监控方式已经无法满足Kubernetes集群的监控需求。
- 需要使用专门针对Kubernetes集群设计的监控工具来监控集群的状态和服务质量。

Prometheus则是目前Kubernetes集群中最常用的监控工具之一，它可以通过Kubernetes API中的 `metrics-server` 获取 `Kubernetes` 集群的指标数据，从而实现对Kubernetes集群的应用层面监控，以及基于它们的水平自动伸缩对象 `HorizontalPodAutoscaler`。



### 、二、Metrics-server

[资源指标管道 **Metrics API** | Kubernetes](https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server)

`Metrics Server` 是一个专门用来收集 Kubernetes 核心资源指标（metrics）的工具，它定时从所有节点的 kubelet 里采集信息，但是对集群的整体性能影响极小，每个节点只大约会占用 1m 的 CPU 和 2MB 的内存，所以性价比非常高。

**Metrics Server 工作原理：**





- [cAdvisor](https://github.com/google/cadvisor): 用于收集、聚合和公开 Kubelet 中包含的容器指标的守护程序。
- [kubelet](https://kubernetes.io/zh-cn/docs/concepts/overview/components/#kubelet): 用于管理容器资源的节点代理。 可以使用 `/metrics/resource` 和 `/stats` kubelet API 端点访问资源指标。
- [Summary API](https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#summary-api-source): kubelet 提供的 API，用于发现和检索可通过 `/stats` 端点获得的每个节点的汇总统计信息。
- [metrics-server](https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server): 集群插件组件，用于收集和聚合从每个 kubelet 中提取的资源指标。 API 服务器提供 Metrics API 以供 HPA、VPA 和 `kubectl top` 命令使用。Metrics Server 是 Metrics API 的参考实现。
- [Metrics API](https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-api): Kubernetes API 支持访问用于工作负载自动缩放的 CPU 和内存。 要在你的集群中进行这项工作，你需要一个提供 Metrics API 的 API 扩展服务器。





![image-20240820215919625](assets/image-20240820215919625.png)





#### 2.1、Metrics-server部署配置

Metrics Server 的项目网址（https://github.com/kubernetes-sigs/metrics-server）

```
$ wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml  && mv components.yaml metrics-server.yaml
```

**修改 YAML 文件**

```
vi metrics-server.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
spec:
  ... ... 
  template:
    spec:
      containers:
      - args:
        - --kubelet-insecure-tls
        ... ... 
```

Metrics Server 默认使用 `TLS 协议`，要验证证书才能与 `kubelet` 实现安全通信，而我们的内网环境里没有这个必要。

默认镜像源非国内，如有下载失败的小伙伴，更改镜像为如下阿里云提供的即可：

```
registry.aliyuncs.com/google_containers/metrics-server:v0.6.1
```

**部署：**

```
$ kubectl apply -f metrics-server.yaml
```

**测试验证：**

```
$ kubectl top node
$ kubectl top pod -n kube-system
```





![image-20240820220108684](assets/image-20240820220108684.png)





![image-20240820220211293](assets/image-20240820220211293.png)







### 三、HorizontalPodAutoscaler

HorizontalPodAutoscaler (HPA)是Kubernetes中的一个控制器，用于动态地调整Pod副本的数量。HPA可以根据Metrics-server提供的指标（如CPU使用率、内存使用率等）或内部指标（如每秒的请求数）来自动调整Pod的副本数量，以确保应用程序具有足够的资源，并且不会浪费资源。

HPA是Kubernetes扩展程序中非常常用的部分，特别是在负载高峰期自动扩展应用程序时。



#### 3.1、使用HorizontalPodAutoscaler

创建一个 Nginx 应用，定义 Deployment 和 Service，作为自动伸缩的目标对象：

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ngx-hpa-dep
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ngx-hpa-dep
  template:
    metadata:
      labels:
        app: ngx-hpa-dep
    spec:
      containers:
      - image: nginx:alpine
        name: nginx
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 50m
            memory: 10Mi
          limits:
            cpu: 100m
            memory: 20Mi
---
apiVersion: v1
kind: Service
metadata:
  name: ngx-hpa-svc
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: ngx-hpa-dep
```



注意在它的 `spec` 里一定要用 `resources` 字段写清楚资源配额，否则 `HorizontalPodAutoscaler` 会无法获取 Pod 的指标，也就无法实现自动化扩缩容。

接下来我们要用命令 `kubectl autoscale` 创建一个 `HorizontalPodAutoscaler` 的样板 YAML 文件，它有三个参数：

- min，Pod 数量的最小值，也就是缩容的下限。
- max，Pod 数量的最大值，也就是扩容的上限。
- cpu-percent，CPU 使用率指标，当大于这个值时扩容，小于这个值时缩容。

现在我们就来为刚才的 Nginx 应用创建 HorizontalPodAutoscaler，指定 Pod 数量最少 2 个，最多 8 个，CPU 使用率指标设置的小一点，5%，方便我们观察扩容现象：

```
$ kubectl autoscale deploy ngx-hpa-dep --min=2 --max=8 --cpu-percent=5 --dry-run=client -o yaml > nginx-demo-hpa.yaml
```

YAML 描述文件：

```
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: ngx-hpa
spec:
  maxReplicas: 8
  minReplicas: 2
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ngx-hpa-dep
  targetCPUUtilizationPercentage: 5
```

通过`kubectl apply`创建这个 `HorizontalPodAutoscaler` 后，它会发现 `Deployment` 里的实例只有 1 个，不符合 min 定义的下限的要求，就先扩容到 2 个：

```
# kubectl get deploy
NAME          READY   UP-TO-DATE   AVAILABLE   AGE
ngx-hpa-dep   1/2     2            1           95s
```



#### 3.2、测试验证

下面我们来给 Nginx 加上压力流量，运行一个测试 Pod，使用的镜像是`httpd:alpine`，它里面有 HTTP 性能测试工具 ab（Apache Bench）：

```
$ kubectl run test -it --image=httpd:alpine -- sh
```

然后我们向 Nginx 发送一百万个请求，持续 1 分钟，再用 `kubectl get hpa` 来观察 `HorizontalPodAutoscaler` 的运行状况：

```
$ ab -c 10 -t 60 -n 1000000 'http://ngx-hpa-svc/'
```

`Metrics Server` 大约每 15 秒采集一次数据，所以 `HorizontalPodAutoscaler` 的自动化扩容和缩容也是按照这个时间点来逐步处理的。

当它发现目标的 CPU 使用率超过了预定的 5% 后，就会以 2 的倍数开始扩容，一直到数量上限，然后持续监控一段时间；

如果 CPU 使用率回落，就会再缩容到最小值 (默认会等待五分钟如果负载没有上去，就会缩小到最低水平，防止抖动)。

```
$ kubectl get po
NAME                           READY   STATUS              RESTARTS   AGE
ngx-hpa-dep-7984687bb9-86cg5   0/1     ContainerCreating   0          14s
ngx-hpa-dep-7984687bb9-9wpr8   1/1     Running             0          29s
ngx-hpa-dep-7984687bb9-gjzwl   0/1     ContainerCreating   0          14s
ngx-hpa-dep-7984687bb9-k4dpj   0/1     ContainerCreating   0          14s
ngx-hpa-dep-7984687bb9-qkhpq   1/1     Running             0          4m45s
ngx-hpa-dep-7984687bb9-sgxtc   0/1     ContainerCreating   0          14s
ngx-hpa-dep-7984687bb9-xq6xk   1/1     Running             0          6m11s
ngx-hpa-dep-7984687bb9-xs9q8   0/1     ContainerCreating   0          29s
```







### 四、总结

- 1、`Metrics Server`是Kubernetes中的一个组件，它可以将集群中的散布的资源使用情况数据收集并聚合起来。收集的数据包括节点的CPU和内存使用情况等。
- 2、通过API提供给`Kubernetes`中的其它组件（如HPA）使用。`Metrics Server`可以帮助集群管理员和应用程序开发者更好的了解集群中资源的使用情况，并根据这些数据做出合理的决策，例如调整Pod副本数、扩展集群等。
- 3、`Metrics Server`对于Kubernetes中的资源管理和应用程序扩展非常重要。





# 7.4、Prometheus黑盒监控



`Prometheus` 监控分为两种：

- 白盒监控
- 黑盒监控

**白盒监控**：是指我们日常监控主机的资源用量、容器的运行状态的运行数据。

**黑盒监控**：常见的黑盒监控包括 `HTTP探针`、`TCP探针`、`Dns`、`Icmp`等用于检测站点、服务的可访问性、服务的连通性，以及访问效率等。

**两者比较**：

- 黑盒监控是以故障为导向当故障发生时，黑盒监控能快速发现故障*。*
- 白盒监控则侧重于主动发现或者预测潜在的问题。

一个完善的监控目标是要能够从白盒的角度发现潜在问题，能够在黑盒的角度快速发现已经发生的问题。

**目前支持的应用场景：**

- ICMP 测试
  - 主机探活机制
- TCP 测试
  - 业务组件端口状态监听
  - 应用层协议定义与监听
- HTTP 测试
  - 定义 Request Header 信息
  - 判断 Http status / Http Respones Header / Http Body 内容
- POST 测试
  - 接口联通性
- SSL 证书过期时间





### 一、Blackbox Exporter 部署

`Exporter Configmap` 定义，可以参考下面两个链接

https://github.com/prometheus/blackbox_exporter/blob/master/CONFIGURATION.md 

https://github.com/prometheus/blackbox_exporter/blob/master/example.yml

首先得声明一个 Blackbox 的 Deployment，并利用 Configmap 来为 Blackbox 提供配置文件。

**Configmap：**

参考 BlackBox Exporter 的 Github 提供的 [示例配置文件](https://github.com/prometheus/blackbox_exporter/blob/master/example.yml)

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: blackbox-exporter
  namespace: monitor
  labels:
    app: blackbox-exporter
data:
  blackbox.yml: |-
    modules:
      ## ----------- DNS 检测配置 -----------
      dns_tcp:  
        prober: dns
        dns:
          transport_protocol: "tcp"
          preferred_ip_protocol: "ip4"
          query_name: "kubernetes.default.svc.cluster.local" # 用于检测域名可用的网址
          query_type: "A" 
      ## ----------- TCP 检测模块配置 -----------
      tcp_connect:
        prober: tcp
        timeout: 5s
      ## ----------- ICMP 检测配置 -----------
      icmp:
        prober: icmp
        timeout: 5s
        icmp:
          preferred_ip_protocol: "ip4"
      ## ----------- HTTP GET 2xx 检测模块配置 -----------
      http_get_2xx:  
        prober: http
        timeout: 10s
        http:
          method: GET
          preferred_ip_protocol: "ip4"
          valid_http_versions: ["HTTP/1.1","HTTP/2"]
          valid_status_codes: [200]           # 验证的HTTP状态码,默认为2xx
          no_follow_redirects: false          # 是否不跟随重定向
      ## ----------- HTTP GET 3xx 检测模块配置 -----------
      http_get_3xx:  
        prober: http
        timeout: 10s
        http:
          method: GET
          preferred_ip_protocol: "ip4"
          valid_http_versions: ["HTTP/1.1","HTTP/2"]
          valid_status_codes: [301,302,304,305,306,307]  # 验证的HTTP状态码,默认为2xx
          no_follow_redirects: false                     # 是否不跟随重定向
      ## ----------- HTTP POST 监测模块 -----------
      http_post_2xx: 
        prober: http
        timeout: 10s
        http:
          method: POST
          preferred_ip_protocol: "ip4"
          valid_http_versions: ["HTTP/1.1", "HTTP/2"]
          #headers:                             # HTTP头设置
          #  Content-Type: application/json
          #body: '{}'                           # 请求体设置
```



**Deployment：**

```
apiVersion: v1
kind: Service
metadata:
  name: blackbox-exporter
  namespace: monitor
  labels:
    k8s-app: blackbox-exporter
spec:
  type: ClusterIP
  ports:
  - name: http
    port: 9115
    targetPort: 9115
  selector:
    k8s-app: blackbox-exporter
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blackbox-exporter
  namespace: monitor
  labels:
    k8s-app: blackbox-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: blackbox-exporter
  template:
    metadata:
      labels:
        k8s-app: blackbox-exporter
    spec:
      containers:
      - name: blackbox-exporter
        image: prom/blackbox-exporter:v0.21.0
        imagePullPolicy: IfNotPresent
        args:
        - --config.file=/etc/blackbox_exporter/blackbox.yml
        - --web.listen-address=:9115
        - --log.level=info
        ports:
        - name: http
          containerPort: 9115
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 50Mi
        livenessProbe:
          tcpSocket:
            port: 9115
          initialDelaySeconds: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          tcpSocket:
            port: 9115
          initialDelaySeconds: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        volumeMounts:
        - name: config
          mountPath: /etc/blackbox_exporter
      volumes:
      - name: config
        configMap:
          name: blackbox-exporter
          defaultMode: 420
# 部署
$ kubectl apply -f blackbox-configmap.yaml
$ kubectl apply -f blackbox-exporter.yaml
# 查看部署后的资源
$ kg all -nmonitor |grep blackbox
```



**定义 BlackBox 在 Prometheus 抓取设置**

> 下面抓取设置，都存放在 `prometheus-config.yaml` 文件中，设置可参考 
>
> https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml





### 二、DNS 监控

```
    - job_name: "kubernetes-dns"
      metrics_path: /probe      # 不是 metrics，是 probe
      params:
        module: [dns_tcp]       # 使用 DNS TCP 模块
      static_configs:
        - targets:
          - kube-dns.kube-system:53     # 不要省略端口号
          - 8.8.4.4:53
          - 8.8.8.8:53
          - 223.5.5.5:53
      relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-exporter.monitor:9115       # 服务地址，和上面的 Service 定义保持一致
```

参数解释：

```
################ DNS 服务器监控 ###################
- job_name: "kubernetes-dns"
  metrics_path: /probe
  params:
    ## 配置要使用的模块,要与blackbox exporter配置中的一致
    ## 这里使用DNS模块
    module: [dns_tcp]
  static_configs:
    ## 配置要检测的地址
    - targets:
      - kube-dns.kube-system:53
      - 8.8.4.4:53
      - 8.8.8.8:53
      - 223.5.5.5
  relabel_configs:
    ## 将上面配置的静态DNS服务器地址转换为临时变量 “__param_target”
    - source_labels: [__address__]
      target_label: __param_target
    ## 将 “__param_target” 内容设置为 instance 实例名称
    - source_labels: [__param_target]
      target_label: instance
    ## BlackBox Exporter 的 Service 地址
    - target_label: __address__
      replacement: blackbox-exporter.monitor:9115
```

更新 `prometheus-config.yaml`配置 :

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```

打开 Prometheus 的 Target 页面，就会看到 上面定义的 `blackbox-k8s-service-dns` 任务；

graph 页面，可以使用 `probe_success` 和 `probe_duration_seconds` 等来检查历史结果。





### 三、ICMP监控

```
    - job_name: icmp-status
      metrics_path: /probe
      params:
        module: [icmp]
      static_configs:
      - targets:
        - 192.10.192.222
        labels:
          group: icmp
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter.monitor:9115
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `blackbox-k8s-http-services` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```





### 四、HTTP 监控（K8S 内部发现方法）



#### 4.1、自定义发现 `Service` 监控 `端口` 和 `路径`

可以如下设置：

```
    - job_name: 'kubernetes-services'
      metrics_path: /probe
      params:
        module:     ## 使用HTTP_GET_2xx与HTTP_GET_3XX模块
        - "http_get_2xx"
        - "http_get_3xx"
      kubernetes_sd_configs:        ## 使用Kubernetes动态服务发现,且使用Service类型的发现
      - role: service
      relabel_configs:      ## 设置只监测Kubernetes Service中Annotation里配置了注解prometheus.io/http_probe: true的service
      - action: keep
        source_labels: [__meta_kubernetes_service_annotation_prometheus_io_http_probe]
        regex: "true"
      - action: replace
        source_labels: 
        - "__meta_kubernetes_service_name"
        - "__meta_kubernetes_namespace"
        - "__meta_kubernetes_service_annotation_prometheus_io_http_probe_port"
        - "__meta_kubernetes_service_annotation_prometheus_io_http_probe_path"
        target_label: __param_target
        regex: (.+);(.+);(.+);(.+)
        replacement: $1.$2:$3$4
      - target_label: __address__
        replacement: blackbox-exporter.monitor:9115     ## BlackBox Exporter 的 Service 地址
      - source_labels: [__param_target]
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        target_label: kubernetes_name   
```



然后，需要在 `Service` 中配置这样的 `annotation` ：

```
annotations:
  prometheus.io/http-probe: "true"      ## 开启 HTTP 探针
  prometheus.io/http-probe-port: "8080"     ## HTTP 探针会使用 8080 端口来进行探测
  prometheus.io/http-probe-path: "/healthCheck"     ## HTTP 探针会请求  /healthCheck  路径来进行探测，以检查应用程序是否正常运行
```



示例：Java应用的svc：

```
apiVersion: v1
kind: Service
metadata:
  name: springboot
  annotations:
    prometheus.io/http-probe: "true"
    prometheus.io/http-probe-port: "8080"
    prometheus.io/http-probe-path: "/apptwo"
spec:
  type: ClusterIP
  selector:
    app: springboot
  ports:
  - name: http
    port: 8080
    protocol: TCP
    targetPort: 8080
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `blackbox-k8s-http-services` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```





#### 4.2、TCP检测

```
    - job_name: "service-tcp-probe"
      scrape_interval: 1m
      metrics_path: /probe
      # 使用blackbox exporter配置文件的tcp_connect的探针
      params:
        module: [tcp_connect]
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      # 保留prometheus.io/scrape: "true"和prometheus.io/tcp-probe: "true"的service
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape, __meta_kubernetes_service_annotation_prometheus_io_tcp_probe]
        action: keep
        regex: true;true
      # 将原标签名__meta_kubernetes_service_name改成service_name
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        regex: (.*)
        target_label: service_name
      # 将原标签名__meta_kubernetes_service_name改成service_name
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        regex: (.*)
        target_label: namespace
      # 将instance改成 `clusterIP:port` 地址
      - source_labels: [__meta_kubernetes_service_cluster_ip, __meta_kubernetes_service_annotation_prometheus_io_http_probe_port]
        action: replace
        regex: (.*);(.*)
        target_label: __param_target
        replacement: $1:$2
      - source_labels: [__param_target]
        target_label: instance
      # 将__address__的值改成 `blackbox-exporter.monitor:9115`
      - target_label: __address__
        replacement: blackbox-exporter.monitor:9115
```



按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `service-tcp-probe` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```



则需要在service上添加注释必须有以下三行

```
  annotations:
    prometheus.io/scrape: "true"        ## 这个服务是可以被采集指标的，Prometheus 可以对这个服务进行数据采集
    prometheus.io/tcp-probe: "true"     ## 开启 TCP 探针
    prometheus.io/http-probe-port: "8080"       ## HTTP 探针会使用 8080 端口来进行探测，以检查应用程序是否正常运行
```



示例：Java应用的svc：

```
apiVersion: v1
kind: Service
metadata:
  name: springboot
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/tcp-probe: "true"
    prometheus.io/http-probe-port: "8080"
spec:
  type: ClusterIP
  selector:
    app: springboot
  ports:
  - name: http
    port: 8080
    protocol: TCP
    targetPort: 8080
```



#### 4.3、Ingress服务的探测（视频中未讲到，扩展+）

```
    - job_name: 'blackbox-k8s-ingresses'
      scrape_interval: 30s
      scrape_timeout: 10s
      metrics_path: /probe
      params:
        module: [http_get_2xx]  # 使用定义的http模块
      kubernetes_sd_configs:
      - role: ingress  # ingress 类型的服务发现
      relabel_configs:
      # 只有ingress的annotation中配置了 prometheus.io/http_probe=true 的才进行发现
      - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_http_probe]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
        regex: (.+);(.+);(.+)
        replacement: ${1}://${2}${3}
        target_label: __param_target
      - target_label: __address__
        replacement: blackbox-exporter.monitor:9115
      - source_labels: [__param_target]
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_ingress_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_ingress_name]
        target_label: kubernetes_name
```



则需要在ingress上添加注释必须有以下三行

```
  annotations:
    prometheus.io/http_probe: "true"
    prometheus.io/http-probe-port: '8080'
    prometheus.io/http-probe-path: '/healthz'
```



示例：Java应用的ing：

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: java-ingress-nginx
  namespace: default
  annotations:
    prometheus.io/http_probe: "true"
    prometheus.io/http-probe-port: '8080'
    prometheus.io/http-probe-path: '/apptwo'
spec:
  ingressClassName: nginx
  rules:
    - host: java.kubernets.cn
      http:
        paths:
          - pathType: Prefix
            backend:
              service:
                name: springboot
                port:
                  number: 8080
            path: /
```





### 五、HTTP 监控（监控外部域名）

```
    - job_name: "blackbox-external-website"
      scrape_interval: 30s
      scrape_timeout: 15s
      metrics_path: /probe
      params:
        module: [http_get_2xx]
      static_configs:
      - targets:
        - https://www.baidu.com # 改为公司对外服务的域名
        - https://www.jd.com
      relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter.monitor:9115
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `blackbox-external-website` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```



### 六、HTTP Post 监控（监控外部域名）

```
    - job_name: 'blackbox-http-post'
      metrics_path: /probe
      params:
        module: [http_post_2xx]
      static_configs:
        - targets:
          - https://www.example.com/api # 要检查的网址
      relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-exporter.monitor:9115
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `blackbox-http-post` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```



### 七、小结

- Blackbox Exporter是一个用于监控网络服务的开源工具。
- 通过模拟HTTP、HTTPS、DNS、TCP等协议向服务端发送请求，并返回响应码、响应时间等信息。
- Blackbox Exporter具有高度的灵活性，可以通过配置文件进行定制，包括对请求的频率、超时时限、请求头、请求参数等进行配置。
- Blackbox Exporter还支持Prometheus监控系统，可以将采集到的数据自动发送给Prometheus，并进行聚合和展示。









# 7.5、自定义资源接入监控系统

Prometheus使用各种Exporter来监控资源。Exporter可以看成是监控的agent端，它负责收集对应资源的指标，并提供接口给到Prometheus读取。



### 一、虚机数据抓取



#### 1.1、配置安装node-exporter

```
docker run -d -p 9100:9100 \
-v "/proc:/host/proc" \
-v "/sys:/host/sys" \
-v "/:/rootfs" \
-v "/etc/localtime:/etc/localtime" \
prom/node-exporter \
--path.procfs /host/proc \
--path.sysfs /host/sys \
--collector.filesystem.ignored-mount-points "^/(sys|proc|dev|host|etc)($|/)"
```



验证数据收集：

```
curl localhost:9100/metrics
```



#### 1.2、配置prometheus-config.yaml

```
    - job_name: 'other-ECS'
      static_configs:
        - targets: ['192.10.192.14:9100']
          labels:
            hostname: 'test-node-exporter'
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `other-ECS` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```





### 二、process-exporter进程监控



#### 2.1、创建挂载目录

```
$ mkdir -p /opt/process-exporter/config
$ cat /opt/process-exporter/config/process-exporter.yml
process_names:
  - name: "{{.Matches}}"
    cmdline:
    - 'sd-api'
```



#### 2.2、配置安装process-exporter

```
docker run -itd --rm -p 9256:9256 --privileged -v /proc:/host/proc -v /opt/process-exporter/config:/config ncabatoff/process-exporter --procfs /host/proc -config.path config/process-exporter.yml
```



#### 2.3、配置文件：

- 匹配 sd-api 的进程（ps -ef | grep sd-api）
- 通过process-exporter的网页去查看监控的数据， 包含：namedprocess_namegroup_num_procs{groupname="map[:sd-api]"} 即代表启动正确

```
## 指定过程进行监控
# cat process-exporter.yml
process_names:
  - name: "{{.Matches}}"
    cmdline:
    - 'sd-api'


#  - name: "{{.Matches}}"
#    cmdline:
#    - 'mysqld'


#  - name: "{{.Matches}}"
#    cmdline:
#    - 'org.apache.zookeeper.server.quorum.QuorumPeerMain'
```



#### 2.4、测试验证

展示当前主机层面的 `sd-api` 这个进程有 `2` 个

```
$ curl localhost:9256/metrics |grep namedprocess_namegroup_num_procs
# HELP namedprocess_namegroup_num_procs number of processes in this group
# TYPE namedprocess_namegroup_num_procs gauge
namedprocess_namegroup_num_procs{groupname="map[:sd-api]"} 2
```



**主机层面命令测试：**

```
# ps aux | grep -v grep | grep sd-api
root     19294  2.6 13.7 7893360 2267104 ?     Ssl  Mar31 1829:10 java -jar /opt/xplatform-sd-api.jar -Dfile.encoding=UTF-8
root     19640  2.6 13.5 7891468 2218288 ?     Ssl  Mar31 1828:54 java -jar /opt/xplatform-sd-api.jar -Dfile.encoding=UTF-8
```



#### 2.5、修改prometheus文件

新增job：

```
    - job_name: 'process-exporter'
      static_configs:
      - targets: ['192.10.192.14:9256']
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `process-exporter` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```





### 三、自定义中间件监控



#### 3.1、创建mysql监听用户并授权，注意服务ip不要填错

```
CREATE USER 'exporter'@'%' IDENTIFIED BY '123asdZXC';
GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'%';
flush privileges;
```



#### 3.2、启动容器

```
docker run -d  --restart=always  --name mysqld-exporter -p 9104:9104 -e DATA_SOURCE_NAME="exporter:123asdZXC@(192.10.192.14:3306)/"  prom/mysqld-exporter
```



#### 3.3、测试验证

```
curl localhost:9104/metrics
```



#### 3.4、修改prometheus文件

新增job：

```
    - job_name: 'mysql-exporter'
      static_configs:
      - targets: ['192.10.192.134:9104']
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `mysql-exporter` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```





### 四、总结

- 1、安装部署自定义 Exporter 组件；
- 2、配置prometheus-config文件做数据抓取；
- 3、配置prometheus-rules做监控告警；
- 4、配置grafana；









#  7.6、基于Consul的自动发现



### 一、背景

[Consul Documentation | Consul | HashiCorp Developer](https://developer.hashicorp.com/consul/docs)

Prometheus配置文件 `prometheus-config.yaml` 配置了大量的采集规则，基本上都是运维小伙伴手动处理，如果后面增加了节点或者组件信息，就得手动修改此配置，并热加载 promethues；那么能否动态的监听微服务呢？Prometheus 提供了多种动态服务发现的功能，这里以 consul 为例。





### 二、基于Consul的自动发现

Consul是分布式k/v数据库，是一个服务注册组件，其他服务都可以注册到consul上，Prometheus也不例外，通过consul的服务发现，我们可以避免在Prometheus中指定大量的target。

prometheus基于consul的服务发现流程如下：

1. 在consul注册服务或注销服务（监控targets）
2. Prometheus一直监视consul服务，当发现consul中符合要求的服务有新变化就会更新Prometheus监控对象





### 三、Prometheus 支持的多种服务发现机制

Prometheus数据源的配置主要分为 **静态配置** 和 **动态发现** , 常用的为以下几类:

```
1）static_configs: #静态服务发现
2）file_sd_configs: #文件服务发现
3）dns_sd_configs: DNS #服务发现
4）kubernetes_sd_configs: #Kubernetes 服务发现
5）consul_sd_configs: Consul #服务发现
```

在监控kubernetes的应用场景中，频繁更新的pod，svc，等资源配置应该是最能体现Prometheus监控目标自动发现服务的好处。





### 四、工作原理

1、Prometheus通过Consul API查询Consul的KV存储中保存的配置信息，然后从中获取关于服务的元数据；

2、Prometheus使用这些信息来构造目标服务的URL，并将其添加到服务发现的目标列表中。

3、当服务被注销或不可用时，Prometheus将自动从其目标列表中删除该服务。 







### 五、容器化Consul集群

测试验证，**不可作为线上使用！** 线上一定要基于集群的方式做整体的部署验证，并做服务进程的守护及监控。

创建一个只有一个节点的consul集群

```
# docker run -id -expose=[8300,8301,8302,8500,8600] --restart always -p 18300:8300 -p 18301:8301 -p 18302:8302 -p 18500:8500 -p 18600:8600 --name server1 -e 'CONSUL_LOCAL_CONFIG={"skip_leave_on_interrupt": true}' consul agent -server -bootstrap-expect=1 -node=server1 -bind=0.0.0.0 -client=0.0.0.0 -ui -datacenter dc1
```



各参数说明：

```
-expose：暴露出出来的端口，即consul启动所需的端口：8300,8301,8302,8500,8600
--restart：always表示容器挂了就自动重启
-p：建立宿主机与容器的端口映射
--name：容器名称
-e：环境变量，这里用于对consul进行配置
consul：这是consul镜像名，不是consul命令
agent：容器中执行的命令，各参数含义：
  -server：表示节点是server类型
  -bootstrap-expect：表示集群中有几个server节点后开始选举leader，既然是单节点集群，那自然就是1了
  -node：节点名称
  -bind：集群内部通信地址，默认是0.0.0.0
  -client：客户端地址，默认是127.0.0.1
  -ui：启用consul的web页面管理
  -datacenter：数据中心
```



**测试验证：**

可通过web端访问，例如：http://192.10.192.109:18500/

```
# curl localhost:18500
```





### 六、注册主机到Consul

例如：将某台虚机上的 `node-exporter` 注册到 consule.



**添加：**

```
## 格式
$ curl -X PUT -d '{"id": "'${host_name}'","name": "node-exporter","address": "'${host_addr}'","port":9100,"tags": ["dam"],"checks": [{"http": "http://'${host_addr}':9100/","interval": "5s"}]}' http://192.10.192.109:18500/v1/agent/service/register


## 示例
$ curl -X PUT -d '{"id": "sh-middler2","name": "node-exporter","address": "192.10.192.134","port":9100,"tags": ["middleware"],"checks": [{"http": "http://192.10.192.134:9100/metrics","interval": "3s"}]}' http://192.10.192.109:18500/v1/agent/service/register


## 参数说明
id : 注册ID 在consul中为唯一标识
name ：Service名称
address：自动注册绑定ip
port：自动注册绑定端口
tags：注册标签，可多个
checks : 健康检查
http:  检查数据来源
interval: 检查时间间隔
http://192.10.192.109:18500/v1/agent/service/register  consul注册接口
```



**删除：**

```
## 格式
$ curl -X PUT http://192.10.192.109:18500/v1/agent/service/deregister/${id}


## 示例
$ curl -X PUT http://192.10.192.109:18500/v1/agent/service/deregister/sh-middler2
```





### 七、Prometheus配置Consul实现自动服务发现

修改prometheus的configmap配置文件：`prometheus-config.yaml`

```
    - job_name: consul
      honor_labels: true
      metrics_path: /metrics
      scheme: http
      consul_sd_configs:    #基于consul服务发现的配置
        - server: 192.10.192.109:18500    #consul的监听地址
          services: []                 #匹配consul中所有的service
      relabel_configs:             #relabel_configs下面都是重写标签相关配置
      - source_labels: ['__meta_consul_tags']    #将__meta_consul_tags标签的至赋值给product
        target_label: 'servername'
      - source_labels: ['__meta_consul_dc']   #将__meta_consul_dc的值赋值给idc
        target_label: 'idc'
      - source_labels: ['__meta_consul_service']   
        regex: "consul"  #匹配为"consul"的service
        action: drop       #执行的动作为删除 
```

按上面方法重载 Prometheus，打开 Prometheus 的 Target 页面，就会看到 上面定义的 `mysql-exporter` 任务

```
curl -XPOST http://prometheus.kubernets.cn/-/reload
```







### 八、总结

- **动态服务发现和监控**：通过与Consul集成，Prometheus可以动态地维护其目标列表，确保在新服务上线时及时发现和监控它们。
- **可扩展性**：自动服务发现使得扩展基础架构变得更加容易，无需担心监控数据的可用性和性能问题。
- **无缝集成**：Consul作为服务注册中心，使得Prometheus可以与Consul生态系统中的其他工具进行无缝集成，提供完整的服务基础架构监控和管理解决方案。
- **自愈能力**：自动服务发现意味着Prometheus可以自动检测服务基础架构的变化，并在实时调整监控目标列表，确保监控数据的连续性和高性能